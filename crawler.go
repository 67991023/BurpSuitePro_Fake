package main

import (
	"fmt"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/gocolly/colly/v2"
)

// 1. Structure ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
type DiscoveryResult struct {
	URLs []string
}

// 2. Wordlist ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fuzzer
var commonPaths = []string{
	"admin", "login", "backup", "config", ".git", ".env", "dashboard",
	"api", "uploads", "test", "db", "administrator",
}

// ==========================================
// üï∏Ô∏è PART A: THE CRAWLER (‡πÅ‡∏°‡∏á‡∏°‡∏∏‡∏°)
// ==========================================
func StartCrawler(targetURL string, allowedDomain string) []string {
	// 1. ‡πÅ‡∏à‡πâ‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Scope ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏≤‡∏ö
	fmt.Printf("\nüï∑Ô∏è Starting Spider on: %s\n", targetURL)
	fmt.Printf("üöß Scope restricted to: %s\n", allowedDomain)

	// ‡πÄ‡∏Å‡πá‡∏ö URL ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
	foundURLs := make(map[string]bool)
	var mu sync.Mutex

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á Collector
	c := colly.NewCollector(
		colly.MaxDepth(2),
		colly.Async(true),
		// 2. ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Domain ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞ www. ‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
		colly.AllowedDomains(allowedDomain, "www."+allowedDomain),
	)

	// ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Delay ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏¢‡∏¥‡∏á‡∏£‡∏±‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
	c.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: 2,
		Delay:       1 * time.Second,
	})

	// ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Link <a>
	c.OnHTML("a[href]", func(e *colly.HTMLElement) {
		link := e.Attr("href")
		absoluteLink := e.Request.AbsoluteURL(link)

		// 3. ‡∏Å‡∏£‡∏≠‡∏á‡∏ã‡πâ‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô (Double Safety)
		// ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Link ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏õ ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ú‡∏™‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
		if !strings.Contains(absoluteLink, allowedDomain) {
			// ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡∏≠‡∏∑‡πà‡∏ô (‡πÄ‡∏ä‡πà‡∏ô twitter.com) ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
			return
		}

		if strings.HasPrefix(absoluteLink, "http") {
			mu.Lock()
			if !foundURLs[absoluteLink] {
				foundURLs[absoluteLink] = true
				fmt.Printf("üï∏Ô∏è [CRAWL] Found: %s\n", absoluteLink)
			}
			mu.Unlock()

			// ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡∏ï‡πà‡∏≠ (Visit) ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç Scope ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
			e.Request.Visit(link)
		}
	})

	// ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡∏à‡∏≤‡∏Å Target ‡πÅ‡∏£‡∏Å
	c.Visit(targetURL)
	c.Wait()

	// ‡πÅ‡∏õ‡∏•‡∏á Map ‡πÄ‡∏õ‡πá‡∏ô Slice ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö
	var results []string
	for u := range foundURLs {
		results = append(results, u)
	}
	return results
}

// ==========================================
// üí£ PART B: THE FUZZER (‡∏ô‡∏±‡∏Å‡πÄ‡∏î‡∏≤‡πÉ‡∏à)
// ==========================================
func StartFuzzer(baseURL string) []string {
	fmt.Printf("\nüí£ Starting Fuzzer on: %s\n", baseURL)

	var foundPaths []string
	var mu sync.Mutex
	var wg sync.WaitGroup

	if !strings.HasSuffix(baseURL, "/") {
		baseURL += "/"
	}

	client := &http.Client{
		Timeout: 5 * time.Second,
	}

	for _, path := range commonPaths {
		wg.Add(1)

		go func(p string) {
			defer wg.Done()

			target := baseURL + p
			resp, err := client.Get(target) // ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö HTTPS ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
			if err != nil {
				return
			}
			defer resp.Body.Close()

			if resp.StatusCode != 404 {
				fmt.Printf("üí£ [FUZZ] Found Hidden Path: %s (Status: %d)\n", target, resp.StatusCode)

				mu.Lock()
				foundPaths = append(foundPaths, target)
				mu.Unlock()
			}
		}(path)
	}

	wg.Wait()
	return foundPaths
}
